{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPZCDURRdQb06diMS/9WNqx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import tensorflow_datasets as tfds\n","import matplotlib.pyplot as plt"],"metadata":{"id":"tauSOVPfvbGc","executionInfo":{"status":"ok","timestamp":1769779278673,"user_tz":-540,"elapsed":14719,"user":{"displayName":"しろカラス","userId":"17237182595459806277"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","#  MNIST データセットの読み込み\n","# ==================================================\n","(ds_train_raw, ds_test_raw), ds_info = tfds.load(\n","    \"mnist\",\n","    split=[\"train\", \"test\"],\n","    shuffle_files=True,\n","    as_supervised=True,\n","    with_info=True\n",")\n","\n","# 前処理\n","def preprocess_train(image, label):\n","    image = tf.cast(image, tf.float32) / 255.0\n","    image = tf.reshape(image, (784,))\n","    return image, image\n","\n","batch_size = 256\n","\n","ds_train = (\n","    ds_train_raw\n","    .map(preprocess_train)\n","    .batch(batch_size)\n","    .prefetch(tf.data.AUTOTUNE)\n",")\n","\n","ds_test = (\n","    ds_test_raw\n","    .map(preprocess_train)\n","    .batch(batch_size)\n","    .prefetch(tf.data.AUTOTUNE)\n",")"],"metadata":{"id":"75ArvI_avh-E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# オートエンコーダの定義\n","# ==================================================\n","# 入力（784次元）\n","input_img = keras.Input(shape=(784,), name=\"input\")\n","\n","# エンコーダ：784 → 256 → 128 → 64 →32\n","x = layers.Dense(256, activation=\"relu\")(input_img)\n","x = layers.Dense(128, activation=\"relu\")(x)\n","x = layers.Dense(64, activation=\"relu\")(x)\n","x = layers.Dense(32, activation=\"relu\")(x)\n","\n","# 潜在表現\n","latent = layers.Dense(32, activation=\"relu\", name=\"latent\")(x)\n","\n","# デコーダ：32 → 64 → 128 → 256 → 784\n","x = layers.Dense(32, activation=\"relu\")(latent)\n","x = layers.Dense(64, activation=\"relu\")(x)\n","x = layers.Dense(128, activation=\"relu\")(x)\n","x = layers.Dense(256, activation=\"relu\")(x)\n","output_img = layers.Dense(784, activation=\"sigmoid\", name=\"output\")(x)\n","\n","autoencoder = keras.Model(input_img, output_img, name=\"autoencoder\")\n","autoencoder.summary()"],"metadata":{"collapsed":true,"id":"ZfKOkzHYvpGb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 学習設定\n","# ==================================================\n","autoencoder.compile(\n","    optimizer=\"adam\",\n","    loss=\"binary_crossentropy\"\n",")\n","\n","# ==================================================\n","# 学習\n","# ==================================================\n","history = autoencoder.fit(\n","    ds_train,\n","    epochs=30,\n","    validation_data=ds_test\n",")"],"metadata":{"id":"6G6VKLJLvtSZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# エンコーダ：入力 → 潜在表現\n","# ==================================================\n","encoder = keras.Model(input_img, latent, name=\"encoder\")\n","\n","sample_batch = next(iter(ds_train))[0]\n","z = encoder(sample_batch)\n","print(\"Latent shape:\", z.shape)\n","\n","# ==================================================\n","# MNIST（ラベル付き）\n","# ==================================================\n","def preprocess_with_label(image, label):\n","    image = tf.cast(image, tf.float32) / 255.0\n","    image = tf.reshape(image, (784,))\n","    return image, label\n","\n","ds_test_vis = (\n","    ds_test_raw\n","    .map(preprocess_with_label)\n","    .batch(batch_size)\n",")"],"metadata":{"id":"glo5m3Y1v07K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 入力画像・再構成画像\n","# ==================================================\n","\n"," # 表示枚数\n","n = 10\n","\n","x_test, y_test = next(iter(ds_test_vis))\n","decoded_imgs = autoencoder.predict(x_test)\n","\n","plt.figure(figsize=(20, 5))\n","\n","for i in range(n):\n","    label_num = int(y_test[i].numpy())\n","\n","    # 入力画像\n","    ax = plt.subplot(2, n, i + 1)\n","    plt.imshow(tf.reshape(x_test[i], (28, 28)), cmap=\"gray\")\n","    plt.title(f\"Input\\nLabel: {label_num}\")\n","    plt.axis(\"off\")\n","\n","    # 再構成画像\n","    ax = plt.subplot(2, n, i + 1 + n)\n","    plt.imshow(tf.reshape(decoded_imgs[i], (28, 28)), cmap=\"gray\")\n","    plt.title(\"Reconstructed\")\n","    plt.axis(\"off\")\n","\n","plt.show()\n","\n","# ==================================================\n","# 学習曲線（損失）\n","# ==================================================\n","plt.figure(figsize=(8, 5))\n","plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n","plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Training and Validation Loss\")\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n"],"metadata":{"id":"Jxv9LluAv46t"},"execution_count":null,"outputs":[]}]}