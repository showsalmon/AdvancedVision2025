{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1769757068709,
     "user": {
      "displayName": "しろカラス",
      "userId": "17237182595459806277"
     },
     "user_tz": -540
    },
    "id": "tauSOVPfvbGc",
    "outputId": "ac16386f-c5dd-4ba0-faf8-dbee2359be8a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1769757100364,
     "user": {
      "displayName": "しろカラス",
      "userId": "17237182595459806277"
     },
     "user_tz": -540
    },
    "id": "75ArvI_avh-E"
   },
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "#  MNIST データセットの読み込み\n",
    "# ==================================================\n",
    "(ds_train_raw, ds_test_raw), ds_info = tfds.load(\n",
    "    \"mnist\",\n",
    "    split=[\"train\", \"test\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "# 前処理\n",
    "def preprocess_train(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.reshape(image, (784,))\n",
    "    return image, image\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "ds_train = (\n",
    "    ds_train_raw\n",
    "    .map(preprocess_train)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "ds_test = (\n",
    "    ds_test_raw\n",
    "    .map(preprocess_train)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 117,
     "status": "ok",
     "timestamp": 1769757123911,
     "user": {
      "displayName": "しろカラス",
      "userId": "17237182595459806277"
     },
     "user_tz": -540
    },
    "id": "ZfKOkzHYvpGb",
    "outputId": "6c63a575-e126-48a4-f92d-54b6e540bfa0"
   },
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# オートエンコーダの定義\n",
    "# ==================================================\n",
    "# 入力（784次元）\n",
    "input_img = keras.Input(shape=(784,), name=\"input\")\n",
    "\n",
    "# エンコーダ：784 → 256 → 128 → 64 →32\n",
    "x = layers.Dense(256, activation=\"relu\")(input_img)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "\n",
    "# 潜在表現\n",
    "latent = layers.Dense(32, activation=\"relu\", name=\"latent\")(x)\n",
    "\n",
    "# デコーダ：32 → 64 → 128 → 256 → 784\n",
    "x = layers.Dense(32, activation=\"relu\")(latent)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "output_img = layers.Dense(784, activation=\"sigmoid\", name=\"output\")(x)\n",
    "\n",
    "autoencoder = keras.Model(input_img, output_img, name=\"autoencoder\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 292383,
     "status": "ok",
     "timestamp": 1769757436734,
     "user": {
      "displayName": "しろカラス",
      "userId": "17237182595459806277"
     },
     "user_tz": -540
    },
    "id": "6G6VKLJLvtSZ",
    "outputId": "4cf8fb14-b323-4033-aec6-813b5ec6194b"
   },
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# 学習設定\n",
    "# ==================================================\n",
    "autoencoder.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\"\n",
    ")\n",
    "\n",
    "# ==================================================\n",
    "# 学習\n",
    "# ==================================================\n",
    "history = autoencoder.fit(\n",
    "    ds_train,\n",
    "    epochs=30,\n",
    "    validation_data=ds_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 121,
     "status": "ok",
     "timestamp": 1769757442502,
     "user": {
      "displayName": "しろカラス",
      "userId": "17237182595459806277"
     },
     "user_tz": -540
    },
    "id": "glo5m3Y1v07K",
    "outputId": "21ed0aa2-beaf-4fe0-b7d0-e34f5b5a7d83"
   },
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# エンコーダ：入力 → 潜在表現\n",
    "# ==================================================\n",
    "encoder = keras.Model(input_img, latent, name=\"encoder\")\n",
    "\n",
    "sample_batch = next(iter(ds_train))[0]\n",
    "z = encoder(sample_batch)\n",
    "print(\"Latent shape:\", z.shape)\n",
    "\n",
    "# ==================================================\n",
    "# MNIST（ラベル付き）\n",
    "# ==================================================\n",
    "def preprocess_with_label(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.reshape(image, (784,))\n",
    "    return image, label\n",
    "\n",
    "ds_test_vis = (\n",
    "    ds_test_raw\n",
    "    .map(preprocess_with_label)\n",
    "    .batch(batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 910
    },
    "executionInfo": {
     "elapsed": 2122,
     "status": "ok",
     "timestamp": 1769757447102,
     "user": {
      "displayName": "しろカラス",
      "userId": "17237182595459806277"
     },
     "user_tz": -540
    },
    "id": "Jxv9LluAv46t",
    "outputId": "12b9bd2d-4651-4405-e97f-cca656ecbd23"
   },
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# 入力画像・再構成画像\n",
    "# ==================================================\n",
    "\n",
    " # 表示枚数\n",
    "n = 10\n",
    "\n",
    "x_test, y_test = next(iter(ds_test_vis))\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "for i in range(n):\n",
    "    label_num = int(y_test[i].numpy())\n",
    "\n",
    "    # 入力画像\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(tf.reshape(x_test[i], (28, 28)), cmap=\"gray\")\n",
    "    plt.title(f\"Input\\nLabel: {label_num}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # 再構成画像\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(tf.reshape(decoded_imgs[i], (28, 28)), cmap=\"gray\")\n",
    "    plt.title(\"Reconstructed\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# ==================================================\n",
    "# 学習曲線（損失）\n",
    "# ==================================================\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPndk6s0/p5LS6Scinw4xPP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
